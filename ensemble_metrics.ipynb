{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import float_info\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_partial_auc_roc(labels, predictions):\n",
    "    min_spec = 0.9\n",
    "    p_aucroc = metrics.roc_auc_score(labels, predictions, max_fpr=(1 - min_spec))\n",
    "    return p_aucroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screening_sens_at_spec(labels, predictions, at_spec=0.95, eps=float_info.epsilon):\n",
    "    y_true = labels\n",
    "    y_pred = predictions\n",
    "\n",
    "    fpr, tpr, threshes = metrics.roc_curve(y_true, y_pred, drop_intermediate=False)\n",
    "    spec = 1 - fpr\n",
    "\n",
    "    operating_points_with_good_spec = spec >= (at_spec - eps)\n",
    "    max_tpr = tpr[operating_points_with_good_spec][-1]\n",
    "\n",
    "    operating_point = np.argwhere(operating_points_with_good_spec).squeeze()[-1]\n",
    "    operating_tpr = tpr[operating_point]\n",
    "\n",
    "    assert max_tpr == operating_tpr or (\n",
    "            np.isnan(max_tpr) and np.isnan(operating_tpr)), f'{max_tpr} != {operating_tpr}'\n",
    "    assert max_tpr == max(tpr[operating_points_with_good_spec]) or (\n",
    "            np.isnan(max_tpr) and max(tpr[operating_points_with_good_spec])), \\\n",
    "        f'{max_tpr} == {max(tpr[operating_points_with_good_spec])}'\n",
    "\n",
    "    return max_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_predition_joined_df(exp_dir, exp_id):\n",
    "    prediction_files = [fn for fn in os.listdir(exp_dir) if fn.startswith('prediction') and exp_id in fn]\n",
    "    dfs = []\n",
    "    for fn in prediction_files:\n",
    "        df = pd.read_csv(os.path.join(exp_dir, fn), index_col=0).set_index('filename')\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_joined = dfs[0].labels\n",
    "    for i, df in enumerate(dfs):\n",
    "        df_joined = pd.merge(df_joined, df['predictions'].rename(f'pred_{i}'), left_index=True, right_index=True)\n",
    "\n",
    "    df_joined['ensamble_prediction'] = df_joined.iloc[:, 1:].mean(axis=1)\n",
    "    return df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(exp_desc, exp_dir, exp_id):\n",
    "    df_joined = _get_predition_joined_df(exp_dir, exp_id)\n",
    "    pauroc = get_partial_auc_roc(df_joined.labels, df_joined.ensamble_prediction)\n",
    "    sens_at_95_spec = screening_sens_at_spec(df_joined.labels, df_joined.ensamble_prediction)\n",
    "    print(f'{exp_desc} ... pauroc {round(pauroc, 4)} ... sens_at_95_spec {round(sens_at_95_spec, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== exp rutger ===\n",
      "yolo baseline OD 1.2 ... pauroc 0.9428 ... sens_at_95_spec 0.9197\n",
      "yolo tuned OD 1.2 ... pauroc 0.9408 ... sens_at_95_spec 0.918\n",
      "\n",
      "=== exp equalisation ===\n",
      "IgnoreBlack OD 1.2 ... pauroc 0.9144 ... sens_at_95_spec 0.8864\n",
      "Yes OD 1.2 ... pauroc 0.9068 ... sens_at_95_spec 0.8644\n",
      "\n",
      "=== exp crops ===\n",
      "OD 2.0 ... pauroc 0.9327 ... sens_at_95_spec 0.9054\n",
      "OD 1.5 ... pauroc 0.9409 ... sens_at_95_spec 0.9274\n",
      "OD 1.2 ... pauroc 0.941 ... sens_at_95_spec 0.9054\n",
      "OD 1.0 ... pauroc 0.9407 ... sens_at_95_spec 0.918\n",
      "FOV 1.2 ... pauroc 0.9389 ... sens_at_95_spec 0.9213\n",
      "no crop ... pauroc 0.8907 ... sens_at_95_spec 0.8391\n",
      "\n",
      "=== exp label smoothing ===\n",
      "base,   OD 1.5 ... pauroc 0.9409 ... sens_at_95_spec 0.9274\n",
      "LS 0.1, OD 1.5 ... pauroc 0.938 ... sens_at_95_spec 0.9148\n",
      "LS 0.5, OD 1.5 ... pauroc 0.9325 ... sens_at_95_spec 0.9054\n",
      "\n",
      "=== exp class imbalance ===\n",
      "base,                   OD 1.5 ... pauroc 0.9409 ... sens_at_95_spec 0.9274\n",
      "FL alpha=0.50, gamma=2, OD 1.5 ... pauroc 0.9404 ... sens_at_95_spec 0.9085\n",
      "FL alpha=0.66, gamma=2, OD 1.5 ... pauroc 0.9391 ... sens_at_95_spec 0.918\n",
      "\n",
      "=== exp aug rotations ===\n",
      "base,   OD 1.5 ... pauroc 0.9409 ... sens_at_95_spec 0.9274\n",
      "rot 10, OD 1.5 ... pauroc 0.944 ... sens_at_95_spec 0.9148\n",
      "rot 20, OD 1.5 ... pauroc 0.9413 ... sens_at_95_spec 0.9211\n",
      "rot 40, OD 1.5 ... pauroc 0.9368 ... sens_at_95_spec 0.9117\n",
      "\n",
      "=== exp aug translations ===\n",
      "base,      OD 1.5 ... pauroc 0.9409 ... sens_at_95_spec 0.9274\n",
      "trans 0.1, OD 1.5 ... pauroc 0.941 ... sens_at_95_spec 0.9148\n",
      "trans 0.2, OD 1.5 ... pauroc 0.9427 ... sens_at_95_spec 0.9117\n",
      "trans 0.4, OD 1.5 ... pauroc 0.9382 ... sens_at_95_spec 0.9117\n",
      "\n",
      "=== exp aug scale ===\n",
      "base,      OD 1.5 ... pauroc 0.9409 ... sens_at_95_spec 0.9274\n",
      "scale 0.1, OD 1.5 ... pauroc 0.9517 ... sens_at_95_spec 0.9464\n",
      "scale 0.2, OD 1.5 ... pauroc 0.944 ... sens_at_95_spec 0.9243\n",
      "scale 0.3, OD 1.5 ... pauroc 0.9392 ... sens_at_95_spec 0.9054\n",
      "\n",
      "=== exp crop finetuning ===\n",
      "OD 1.4 ... pauroc 0.9448 ... sens_at_95_spec 0.9085\n",
      "OD 1.5 ... pauroc 0.944 ... sens_at_95_spec 0.9211\n",
      "OD 1.6 ... pauroc 0.9455 ... sens_at_95_spec 0.9243\n",
      "\n",
      "=== exp models ===\n",
      "tv-224-swin_b.IMAGENET1K_V1 ... pauroc 0.9445 ... sens_at_95_spec 0.9274\n",
      "tv-224-resnext50_32x4d.IMAGENET1K_V2 ... pauroc 0.8793 ... sens_at_95_spec 0.8233\n",
      "tv-384vit_b_16.IMAGENET1K_SWAG_E2E_V1 ... pauroc 0.9479 ... sens_at_95_spec 0.9274\n",
      "google/vit-base-patch32-384 ... pauroc 0.9114 ... sens_at_95_spec 0.8675\n",
      "tv-224-vit_b_32.IMAGENET1K_V1 ... pauroc 0.8816 ... sens_at_95_spec 0.8139\n",
      "tv-224vit_b_16.IMAGENET1K_SWAG_LINEAR_V1 ... pauroc 0.8929 ... sens_at_95_spec 0.8549\n",
      "microsoft/swin-base-patch4-window12-384-in22k ... pauroc 0.9473 ... sens_at_95_spec 0.9274\n",
      "microsoft/swin-large-patch4-window12-384-in22k ... pauroc 0.936 ... sens_at_95_spec 0.8959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=== exp rutger ===')\n",
    "get_metrics('yolo baseline OD 1.2', 'experiments/exp_yolo', 'h0b29272b94d2f51a')\n",
    "get_metrics('yolo tuned OD 1.2', 'experiments/exp_yolo', 'h7010ed743c685d8c')\n",
    "print()\n",
    "\n",
    "print('=== exp equalisation ===')\n",
    "get_metrics('IgnoreBlack OD 1.2', 'experiments/exp_equalisation', 'h699162adab7f35c3')\n",
    "get_metrics('Yes OD 1.2', 'experiments/exp_equalisation', 'h76044e9d122a305e')\n",
    "print()\n",
    "\n",
    "print('=== exp crops ===')\n",
    "get_metrics('OD 2.0', 'experiments/exp_crops', 'h2a932ca21a6567b5')\n",
    "get_metrics('OD 1.5', 'experiments/exp_crops', 'h8e023b47e3641bb7')\n",
    "get_metrics('OD 1.2', 'experiments/exp_crops', 'h5d2652f50e1bd942')\n",
    "get_metrics('OD 1.0', 'experiments/exp_crops', 'hec9dc788fd725a32')\n",
    "get_metrics('FOV 1.2', 'experiments/exp_crops', 'h5e77f73fb6cb1d37')\n",
    "get_metrics('no crop', 'experiments/exp_crops', 'h76f5996b2c96146a')\n",
    "print()\n",
    "\n",
    "print('=== exp label smoothing ===')\n",
    "get_metrics('base,   OD 1.5', 'experiments/exp_crops', 'h8e023b47e3641bb7')\n",
    "get_metrics('LS 0.1, OD 1.5', 'experiments/exp_label_smoothing', 'h07af68425afb3d25')\n",
    "get_metrics('LS 0.5, OD 1.5', 'experiments/exp_label_smoothing', 'hbe0385eca404c827')\n",
    "print()\n",
    "\n",
    "print('=== exp class imbalance ===')\n",
    "get_metrics('base,                   OD 1.5', 'experiments/exp_crops', 'h8e023b47e3641bb7')\n",
    "get_metrics('FL alpha=0.50, gamma=2, OD 1.5', 'experiments/exp_class_imbalance', 'h7610d694a6a38511')\n",
    "get_metrics('FL alpha=0.66, gamma=2, OD 1.5', 'experiments/exp_class_imbalance', 'h08194bb70b6cd18c')\n",
    "print()\n",
    "\n",
    "print('=== exp aug rotations ===')\n",
    "get_metrics('base,   OD 1.5', 'experiments/exp_crops', 'h8e023b47e3641bb7')\n",
    "get_metrics('rot 10, OD 1.5', 'experiments/exp_rotations', 'h80e50dc8930f5af6')\n",
    "get_metrics('rot 20, OD 1.5', 'experiments/exp_rotations', 'h1f9e2f2bd7c8736d')\n",
    "get_metrics('rot 40, OD 1.5', 'experiments/exp_rotations', 'h458a6e2eae2eb24b')\n",
    "print()\n",
    "\n",
    "print('=== exp aug translations ===')\n",
    "get_metrics('base,      OD 1.5', 'experiments/exp_crops', 'h8e023b47e3641bb7')\n",
    "get_metrics('trans 0.1, OD 1.5', 'experiments/exp_translations', 'h71d58c99ab50c2e6')\n",
    "get_metrics('trans 0.2, OD 1.5', 'experiments/exp_translations', 'hee6293b663deaf96')\n",
    "get_metrics('trans 0.4, OD 1.5', 'experiments/exp_translations', 'h275dd8fff7dcdfcb')\n",
    "print()\n",
    "\n",
    "print('=== exp aug scale ===')\n",
    "get_metrics('base,      OD 1.5', 'experiments/exp_crops', 'h8e023b47e3641bb7')\n",
    "get_metrics('scale 0.1, OD 1.5', 'experiments/exp_aug_scale', 'h2faf4dc885212e0a')\n",
    "get_metrics('scale 0.2, OD 1.5', 'experiments/exp_aug_scale', 'h20a4622db1030415')\n",
    "get_metrics('scale 0.3, OD 1.5', 'experiments/exp_aug_scale', 'h9d3fe6e7b588c20f')\n",
    "print()\n",
    "\n",
    "print('=== exp crop finetuning ===')\n",
    "get_metrics('OD 1.4', 'experiments/exp_crop_finetuning', 'ha21122c64b5683dc')\n",
    "get_metrics('OD 1.5', 'experiments/exp_crop_finetuning', 'h6d2ee23d32630cd4')\n",
    "get_metrics('OD 1.6', 'experiments/exp_crop_finetuning', 'ha133aee1531aa717')\n",
    "print()\n",
    "\n",
    "print('=== exp models ===')\n",
    "get_metrics('tv-224-swin_b.IMAGENET1K_V1', 'experiments/exp_models', 'h9efeed964a992c45')\n",
    "get_metrics('tv-224-resnext50_32x4d.IMAGENET1K_V2', 'experiments/exp_models', 'h2c8398d4f31283b2')\n",
    "get_metrics('tv-384vit_b_16.IMAGENET1K_SWAG_E2E_V1', 'experiments/exp_models', 'h97a0c08e98ae681d')\n",
    "get_metrics('google/vit-base-patch32-384', 'experiments/exp_models', 'h8331ca3d520e56c0')\n",
    "get_metrics('tv-224-vit_b_32.IMAGENET1K_V1', 'experiments/exp_models', 'hb3383ce03e7723ea')\n",
    "get_metrics('tv-224vit_b_16.IMAGENET1K_SWAG_LINEAR_V1', 'experiments/exp_models', 'hc12b18639f424729')\n",
    "get_metrics('microsoft/swin-base-patch4-window12-384-in22k', 'experiments/exp_models', 'hd481a4d8b4967120')\n",
    "get_metrics('microsoft/swin-large-patch4-window12-384-in22k', 'experiments/exp_models', 'hbdb18e177ce20ad5')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp submission tuning 2 ... pauroc 0.9485 ... sens_at_95_spec 0.9432\n",
      "exp submission tuning 2 1.5 ... pauroc 0.9517 ... sens_at_95_spec 0.9464\n",
      "exp submission tuning 2 1.6 ... pauroc 0.95 ... sens_at_95_spec 0.9274\n"
     ]
    }
   ],
   "source": [
    "get_metrics('exp submission tuning 2', 'experiments/exp_submission_tuning2_coloraug', 'h67cf051ba2a4f657')\n",
    "get_metrics('exp submission tuning 2 1.5', 'experiments/exp_submission_tuning2', 'h67cf051ba2a4f657')\n",
    "get_metrics('exp submission tuning 2 1.6', 'experiments/exp_submission_tuning2', 'hca71f1dd231aa149')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
