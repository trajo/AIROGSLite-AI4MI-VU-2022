{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add yolo results to dataframe, compute od in original image, save images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import src.preprocessing as ppc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/shuffled_square_75/img_info.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract predictions and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng = []\n",
    "\n",
    "for filename in tqdm(os.listdir(\"data/labels\")):\n",
    "    predictions = open(f\"data/labels/{filename}\", \"r\").read()\n",
    "    predictions = predictions.split(\"\\n\")[:-1]\n",
    "    predictions = [pred.split() for pred in predictions]\n",
    "    leng.append(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(leng)\n",
    "count # in 117 instances we only have 1 prediction \n",
    "# (I checked, its like half/half fovea or OD. so like 50 ODs are missing but in that case we can just use the full retina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(\"data/labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for filename in tqdm(os.listdir(\"data/labels\")):\n",
    "    key = filename[:-4]\n",
    "    with open(f\"data/labels/{filename}\", \"r\") as f:\n",
    "        odc = [None] * 5\n",
    "        fovea = [None] * 5\n",
    "        for line in f.readlines():\n",
    "            pred = [float(number) for number in line.split()]\n",
    "            if pred[0]==0:\n",
    "                odc=pred[1:]\n",
    "            if pred[0]==1:\n",
    "                fovea=pred[1:]\n",
    "\n",
    "        record = [key,]\n",
    "        record.extend(odc)\n",
    "        record.extend(fovea)\n",
    "        records.append(tuple(record))\n",
    "\n",
    "df_to_join = pd.DataFrame.from_records(records, columns=[\n",
    "    'new_file',\n",
    "    'odc_x_ratio', 'odc_y_ratio', 'odc_width_ratio', 'odc_height_ratio', 'odc_conf',\n",
    "    'fovea_x_ratio', 'fovea_y_ratio', 'fovea_width_ratio', 'fovea_height_ratio', 'fovea_conf'])\n",
    "\n",
    "max_fovea = df_to_join.fovea_conf.max()\n",
    "max_odx = df_to_join.odc_conf.max()\n",
    "df = pd.merge(df.reset_index(), df_to_join, how='left', on='new_file')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate OD size and center on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fovea_x_square\"] = round(df.orig_crop_side * df.fovea_x_ratio, 0)\n",
    "df[\"odc_x_square\"] = round(df.orig_crop_side * df.odc_x_ratio, 0)\n",
    "df[\"fovea_y_square\"] = round(df.orig_crop_side * df.fovea_y_ratio, 0)\n",
    "df[\"odc_y_square\"] = round(df.orig_crop_side * df.odc_y_ratio, 0)\n",
    "df[\"od_side_ratio_avg\"] = (df.odc_height_ratio + df.odc_width_ratio)/2\n",
    "df[\"odc_side_pxl\"] = round(df.orig_crop_side * df.od_side_ratio_avg, 0)\n",
    "df[\"odc_x_rect\"] = df.odc_x_square - df.delta_y # it seems like delta x refers to how many pixels are cut of from the top and delta_y to the left\n",
    "df[\"odc_y_rect\"] = df.odc_y_square - df.delta_x\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/img_info_extended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/img_info_extended.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTOR = 1.5\n",
    "THRESHOLD = 10\n",
    "MULTIPROCESSING_WORKERS = 8\n",
    "RESOLUTION = 384\n",
    "INTERPOLATION_METHOD = cv2.INTER_CUBIC\n",
    "DATA_DIR = f'./data/ods_center_{FACTOR}_{RESOLUTION}_{INTERPOLATION_METHOD}'\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    print(f'{DATA_DIR} does not exist, creating dir')\n",
    "    os.mkdir(DATA_DIR)\n",
    "\n",
    "def process_file(filename):\n",
    "    img = cv2.imread(f\"data/cfp/{filename}\")\n",
    "    img_data = df.loc[df.orig_file == filename]\n",
    "    write_filename = f'{img_data.new_file.values[0]}.png'\n",
    "    if img_data.odc_x_rect.isna().values[0]:\n",
    "        # TODO: This is not correct, a separate model should be trained for images without an optic disc being detected\n",
    "        img_square, _, _ = ppc.make_square(img, THRESHOLD)\n",
    "        img_res = ppc.resize_square(img_square, RESOLUTION)\n",
    "        cv2.imwrite(f\"{DATA_DIR}/{write_filename}\", img_res)\n",
    "    else:\n",
    "        add_top = (img.shape[0] - img_data.side)/2\n",
    "        add_left = (img.shape[1] - img_data.side)/2\n",
    "        odc_x_rect = int(img_data.odc_x_square.values[0] + add_left)\n",
    "        odc_y_rect = int(img_data.odc_y_square.values[0] + add_top)\n",
    "\n",
    "        #od = ppc.crop_od(img, odc_x_rect, odc_y_rect, int(img_data.odc_side_pxl.values[0]*FACTOR))\n",
    "        od = ppc.crop_od_fill_if_needed(img, odc_x_rect, odc_y_rect, int(img_data.odc_side_pxl.values[0]*FACTOR))\n",
    "\n",
    "        od_res = ppc.resize_square(od, RESOLUTION)\n",
    "        #print(write_filename)\n",
    "        cv2.imwrite(f\"{DATA_DIR}/{write_filename}\", od_res) # png because it is lossless\n",
    "\n",
    "cfp_files = os.listdir(\"data/cfp\")\n",
    "if MULTIPROCESSING_WORKERS > 1:\n",
    "    from multiprocessing import Pool\n",
    "    with Pool(MULTIPROCESSING_WORKERS) as pool:\n",
    "        op_metadata = list(tqdm(pool.imap(process_file, cfp_files), total=len(cfp_files)))\n",
    "    print('Finished.')\n",
    "else:\n",
    "    for filename in tqdm(os.listdir(\"data/cfp\")):\n",
    "        process_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('airogs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "061bd6094ad0c8a3908ed2966c1aa3f09fb3cf99cdbbdc5979d65ee9ea258955"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
