{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from src.transformations import EqualizeTransform, CenterCrop, Translate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'DEV13781.jpg'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('original_shuffled_map.json') as fp:\n",
    "    original_shuffled_map = json.load(fp)\n",
    "list(original_shuffled_map.keys())[list(original_shuffled_map.values()).index(\"SHUF00000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_class_labels_df(cls_labels_file):  # e.g. 'data/dev_labels.csv'\n",
    "    cls_labels = pd.read_csv(cls_labels_file)\n",
    "    cls_labels['id'] = cls_labels['aimi_id']\n",
    "    cls_labels['label_num'] = (cls_labels['class'] == 'RG').astype(int)\n",
    "    cls_labels = cls_labels.drop(columns=['aimi_id', 'class'])\n",
    "    cls_labels = cls_labels.set_index('id')\n",
    "    return cls_labels\n",
    "\n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, data_dir, df_labels, cache_all=False, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.cache_all = cache_all\n",
    "        self.data = {}\n",
    "        self.df_labels = df_labels.reset_index().sort_values(by='filename', ascending=True)\n",
    "        self.filenames = self.df_labels.filename.to_numpy()\n",
    "\n",
    "        if self.cache_all:\n",
    "            for i, fn in enumerate(self.filenames):\n",
    "                filepath = os.path.join(self.data_dir, fn)\n",
    "                img = Image.open(filepath).convert('RGB')  # convert forces the image to load in the main process\n",
    "                # ...other, since PIL uses lazy loading, would cause the image to be loaded in the dataloader\n",
    "                # worker process but PIL has issues with multiprocessing\n",
    "                self.data[i] = img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def _get_data(self, idx):\n",
    "        if self.cache_all:\n",
    "            return self.data[idx]\n",
    "        else:\n",
    "            fn = self.filenames[idx]\n",
    "            filepath = os.path.join(self.data_dir, fn)\n",
    "            img = Image.open(filepath).convert('RGB')\n",
    "            return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = self._get_data(idx)\n",
    "\n",
    "        # apply transforms\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = int(self.df_labels.iloc[idx].label_num)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    @staticmethod\n",
    "    def add_argparse_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\n",
    "            title=\"MyDataModule\", description=\"Class to organize and manage the data\"\n",
    "        )\n",
    "        parser.add_argument('--data_dir', type=str, default='./data/cfp_od_crop_OD_f2.0')\n",
    "        parser.add_argument('--cls_label_file', default='./data/dev_labels.csv')\n",
    "        parser.add_argument(\"--equalize\", choices=[\"no\", \"yes\", \"IgnoreBlack\"], default=\"no\")\n",
    "        parser.add_argument(\"--batch_size\", default=8, type=int)\n",
    "        parser.add_argument(\"--use_validation_set_for_test\", action=\"store_true\")\n",
    "        parser.add_argument(\"--od_crop_factor\", default=1.0, type=float)\n",
    "        parser.add_argument(\"--aug_degrees\", default=45, type=float)\n",
    "        parser.add_argument(\"--aug_translate\", default=0, type=float)\n",
    "        parser.add_argument(\"--aug_scale\", default=0.0, type=float)\n",
    "        parser.add_argument(\"--split_num_val_folds\", default=5, type=int)\n",
    "        parser.add_argument(\"--split_val_fold_idx\", default=4, type=int)\n",
    "        parser.add_argument(\"--split_test_prop\", default=0.0, type=float)\n",
    "        parser.add_argument(\"--DATA_MAX_OD_DIAMETER_PROP\",\n",
    "                            default=2.0,\n",
    "                            help=\"needs to match data generated with lossless_od_crops_using_yolo_predictions.ipynb\")\n",
    "        parser.add_argument(\"--DATA_CROP_ENLARGMENT_FACTOR\",\n",
    "                            default=2**0.5 * 1.01,  # so that a rotation of the area of interest will not show an artificial border\n",
    "                            help=\"needs to match data generated with  lossless_od_crops_using_yolo_predictions.ipynb\")\n",
    "        return parent_parser\n",
    "\n",
    "    def __init__(self, args, backbone_transform, backbone_resize):\n",
    "        super().__init__()\n",
    "\n",
    "        max_od_diameter_prop = args.DATA_MAX_OD_DIAMETER_PROP\n",
    "        crop_enlargment_factor = args.DATA_CROP_ENLARGMENT_FACTOR\n",
    "        crop_factor = args.od_crop_factor / (max_od_diameter_prop * crop_enlargment_factor)\n",
    "        aug_translate = args.aug_translate / (max_od_diameter_prop * crop_enlargment_factor)\n",
    "\n",
    "        df_labels = _get_class_labels_df(args.cls_label_file).sort_index(ascending=True)\n",
    "\n",
    "        equalizer = EqualizeTransform(args)\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            equalizer,\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.RandomAffine(degrees=args.aug_degrees,\n",
    "                                        translate=(aug_translate/2, aug_translate/2),\n",
    "                                        scale=None)],  # random scaling is done through the cropping\n",
    "                p=1.0),\n",
    "            CenterCrop(crop_factor, args.aug_scale/2),\n",
    "            backbone_resize,\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            backbone_transform,\n",
    "        ])\n",
    "\n",
    "        self.test_transforms = transforms.Compose([\n",
    "            equalizer,\n",
    "            transforms.ToTensor(),\n",
    "            CenterCrop(crop_factor),\n",
    "            backbone_resize,\n",
    "            backbone_transform,\n",
    "        ])\n",
    "\n",
    "        datadir_filenames = [fn for fn in os.listdir(args.data_dir) if fn.endswith('.png')]\n",
    "        fn_df = pd.DataFrame(columns=['filename'], data=datadir_filenames)\n",
    "        fn_df['id'] = fn_df['filename'].map(lambda x: x[:-4])\n",
    "        fn_df = fn_df.set_index('id')\n",
    "        df_labels = pd.merge(fn_df, df_labels, how='left', left_index=True, right_index=True)  # note the left join\n",
    "        df_labels = df_labels.sort_index(ascending=True)\n",
    "\n",
    "        devset_len = int(len(df_labels) * (1-args.split_test_prop))\n",
    "        test_mask = np.zeros(len(df_labels), dtype=bool)\n",
    "        test_mask[devset_len:-1] = True\n",
    "\n",
    "        fold_val = np.zeros(len(df_labels), dtype=bool)\n",
    "        val_cnt = devset_len // args.split_num_val_folds\n",
    "        if args.split_val_fold_idx < args.split_num_val_folds:\n",
    "            fold_val[args.split_val_fold_idx * val_cnt:(args.split_val_fold_idx+1) * val_cnt] = True\n",
    "        else:\n",
    "            fold_val[args.split_val_fold_idx * val_cnt:devset_len] = True\n",
    "        fold_train = (~fold_val) & (~test_mask)\n",
    "\n",
    "        self.train_ds = ClassifierDataset(args.data_dir, df_labels=df_labels[fold_train],\n",
    "                                          cache_all=False,\n",
    "                                          transform=self.train_transforms)\n",
    "        self.val_ds = ClassifierDataset(args.data_dir, df_labels=df_labels[fold_val],\n",
    "                                        cache_all=False,\n",
    "                                        transform=self.test_transforms)\n",
    "        if args.split_test_prop == 0:\n",
    "            self.test_ds = self.val_ds\n",
    "        else:\n",
    "            self.test_ds = ClassifierDataset(args.data_dir, df_labels=df_labels[test_mask],\n",
    "                                             cache_all=False,\n",
    "                                             transform=self.test_transforms)\n",
    "        self.batch_size = args.batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, shuffle=True, batch_size=self.batch_size,\n",
    "                          num_workers=6, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size,\n",
    "                          num_workers=6, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size,\n",
    "                          num_workers=6, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser = MyDataModule.add_argparse_args(parser)\n",
    "args = parser.parse_args({})\n",
    "\n",
    "data = MyDataModule(args,\n",
    "                    backbone_transform=transforms.Lambda(lambda x: x), # a no-op\n",
    "                    backbone_resize=transforms.Resize((224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "batch = next(iter(data.train_dataloader()))\n",
    "tr = transforms.ToPILImage()\n",
    "for i in range(8):\n",
    "    im = batch[0][i, :, :, :]\n",
    "    pil_im = tr(im)\n",
    "    pil_im.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('airogs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "061bd6094ad0c8a3908ed2966c1aa3f09fb3cf99cdbbdc5979d65ee9ea258955"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
